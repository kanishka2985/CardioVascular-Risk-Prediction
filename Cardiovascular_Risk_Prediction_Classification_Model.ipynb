{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanishka2985/CardioVascular-Risk-Prediction/blob/main/Cardiovascular_Risk_Prediction_Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Cardiovascular Risk Prediction Project\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name**            - Kanishka Sharma\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Cardiovascular diseases (CVDs) are among the leading causes of death worldwide, claiming millions of lives every year. Early detection and timely medical intervention play a critical role in reducing mortality and improving the quality of life for patients. However, traditional methods of identifying individuals at risk often involve time‑consuming processes, invasive procedures, or are performed too late in the disease’s progression. With the increasing availability of patient health data, machine learning offers an effective and efficient way to predict the risk of cardiovascular disease at an early stage. This project focuses on building and evaluating different machine learning models to accurately predict heart disease risk based on various patient attributes.\n",
        "\n",
        "The dataset used in this project contains clinical, demographic, and lifestyle information of patients. Key features include parameters like age, gender, cholesterol levels, resting blood pressure, maximum heart rate, blood sugar levels, and other relevant medical indicators. Before modeling, data preprocessing steps such as handling missing values, encoding categorical variables, and scaling numerical features were performed. Exploratory data analysis helped in understanding data patterns, detecting outliers, and visualizing relationships between variables and the target outcome. These steps were crucial to ensure that the data fed into the models was clean, consistent, and meaningful.\n",
        "\n",
        "Several machine learning models were implemented and tested to find the most effective predictor. The models included Logistic Regression, Decision Tree, Random Forest, and XGBoost, both with their default parameters and after hyperparameter tuning. Each model was trained on the dataset and evaluated on unseen test data. To measure their performance, we considered four key metrics: precision, recall, F1 score, and ROC‑AUC. Precision reflects how many predicted positives are actually correct, while recall measures how many actual positives were detected by the model. The F1 score provides a balance between precision and recall, and the ROC‑AUC shows the model’s ability to distinguish between positive and negative classes across all thresholds.\n",
        "\n",
        "After evaluating all the models, XGBoost with default parameters emerged as the best performing model. It achieved a high F1 score, demonstrating a good balance between catching true heart‑risk patients and avoiding false alarms. Its high recall ensured that most high‑risk patients were correctly identified, while its strong precision minimized unnecessary follow‑up tests. The ROC‑AUC score further confirmed its strong ability to separate high‑risk and low‑risk individuals. Although a tuned version of XGBoost was also tested, it showed a slight improvement in precision but a drop in recall, which could lead to more missed high‑risk patients. In a healthcare setting, missing a true positive is more critical than handling a few false positives, so the default XGBoost model was chosen.\n",
        "\n",
        "The results from this project highlight the potential of machine learning in supporting clinical decision‑making. By identifying high‑risk patients early, medical professionals can prioritize those in need of further diagnostic testing or preventive care. This not only improves patient outcomes but also optimizes the use of healthcare resources by reducing unnecessary procedures. The chosen model can be further enhanced by integrating additional patient data, regularly retraining with new information, and collaborating with medical experts to fine‑tune its predictions.\n",
        "\n",
        "In conclusion, this project successfully demonstrates how data‑driven techniques can be applied to a critical healthcare problem. Through careful data preparation, model selection, and performance evaluation, we developed an XGBoost model that can effectively predict cardiovascular disease risk. This approach provides a valuable tool for early intervention, offering both clinical and economic benefits. Future work may involve deploying the model in real‑time hospital systems, testing it on larger datasets, and exploring explainability techniques to help clinicians understand the reasoning behind each prediction. Ultimately, projects like this mark a step forward in combining technology with medicine to save lives and improve care.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link For The Project -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/kanishka2985/CardioVascular-Risk-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Links-"
      ],
      "metadata": {
        "id": "s0-cZN6-MMgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github Link:- https://github.com/kanishka2985\n",
        "\n",
        "LinkedIn Link:- www.linkedin.com/in/kanishka2985"
      ],
      "metadata": {
        "id": "zbkYaeflMQMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide, accounting for millions of deaths each year. Early detection and accurate prediction of CVD risk are crucial for timely intervention, improved patient outcomes, and reduced healthcare costs. However, traditional diagnostic methods often rely on invasive procedures or are applied too late in the disease progression.\n",
        "\n",
        "Given a dataset of patient health records—including clinical, demographic, and lifestyle variables—the goal is to develop and evaluate machine learning models that can predict whether a patient is at risk of developing cardiovascular disease.\n",
        "\n",
        "The challenge is to identify patterns and relationships within the data that allow for high predictive performance while maintaining interpretability for clinical use.\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the necessary Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import plotly.express as px\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3seib1648ufI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "path='/content/drive/MyDrive/Colab Notebooks/cardiovascular risk prediction dataset/Copy of data_cardiovascular_risk.csv'\n",
        "df=pd.read_csv(path)"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(),cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through the dataset we can see that:-\n",
        "1. The Cardiovascular Dataset has **3390** rows and **17** columns in it.\n",
        "2.  **No data is being repeated** in the dataset which makes it quite clean\n",
        "3. But the dataset **contain null values** ,with `glucose` having the highest NaN values in it:-\n",
        "* `education`- 87 NaN values\n",
        "* `cigsPerDay`- 22 NaN values\n",
        "* `BPMeds`-\t44 NaN values\n",
        "* `totChol`-\t38 NaN values\n",
        "* `BMI`-\t14 NaN values\n",
        "* `glucose`-\t304 NaN values\n",
        "* `heartRate`- 1 NaN value\n",
        "* Therefore, handling of these NaN values should be done before modeling.\n",
        "4. The columns contain **3 different datatypes** (i.e.,float64,object,int64):\n",
        "* **Nine Float Columns** (i.e., `education`,`cigsPerDay`,`BPMeds`,`totChol`,           `sysBP`,`diaBP`,`BMI`,`heartRate`,`glucose`)\n",
        "* **Six Int Columns** (i.e.,`id`,'`age`,`prevalentStroke`,`prevalentHyp`,`diabetes`,`TenYearCHD`)\n",
        "* **Two Object Columns** (i.e., `sex`,`is_smoking`)\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Variable**      | **Description**                                                                   |\n",
        "| ----------------- | --------------------------------------------------------------------------------- |\n",
        "| `id`              | Unique identifier for each individual (can be dropped for modeling)               |\n",
        "| `age`             | Age of the person (in years)                                                      |\n",
        "| `education`       | Education level (1 = lowest, 4 = highest)                                         |\n",
        "| `sex`             | Biological sex (F = Female, M = Male)                                             |\n",
        "| `is_smoking`      | Whether the person is currently a smoker (YES or NO)                              |\n",
        "| `cigsPerDay`      | Number of cigarettes smoked per day (0 if non-smoker)                             |\n",
        "| `BPMeds`          | Is the person on blood pressure medication? (1 = Yes, 0 = No)                     |\n",
        "| `prevalentStroke` | Has the person ever had a stroke? (1 = Yes, 0 = No)                               |\n",
        "| `prevalentHyp`    | Has the person ever had hypertension? (1 = Yes, 0 = No)                           |\n",
        "| `diabetes`        | Whether the person has diabetes (1 = Yes, 0 = No)                                 |\n",
        "| `totChol`         | Total cholesterol level (mg/dL)                                                   |\n",
        "| `sysBP`           | Systolic blood pressure (mmHg)                                                    |\n",
        "| `diaBP`           | Diastolic blood pressure (mmHg)                                                   |\n",
        "| `BMI`             | Body Mass Index = weight / (height²), indicator of body fat                       |\n",
        "| `heartRate`       | Heart rate in beats per minute (BPM)                                              |\n",
        "| `glucose`         | Glucose level in mg/dL                                                            |\n",
        "| `TenYearCHD`      | Target variable: Risk of coronary heart disease within 10 years (1 = Yes, 0 = No) |\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.copy()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#maximum age value\n",
        "df['age'].max()"
      ],
      "metadata": {
        "id": "E-28nn0B16dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#minimum age value\n",
        "df['age'].min()"
      ],
      "metadata": {
        "id": "BikT9agJ1-Mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling the null values\n",
        "\n",
        "# Impute categorical columns with mode\n",
        "df['education'].fillna(df['education'].mode()[0], inplace=True)\n",
        "df['BPMeds'].fillna(df['BPMeds'].mode()[0], inplace=True)\n",
        "\n",
        "#Drop only rows where heartRate is missing\n",
        "df = df.dropna(subset=['heartRate'])\n",
        "\n",
        "# Impute numerical columns with median\n",
        "num_cols = ['cigsPerDay', 'totChol', 'BMI','glucose']\n",
        "for col in num_cols:\n",
        "    df[col].fillna(df[col].median(), inplace=True)"
      ],
      "metadata": {
        "id": "wvaiFNgv_fps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a new feature 'pulse_pressure' by subtracting diastolic BP from systolic BP\n",
        "df['pulse_pressure'] = df['sysBP'] - df['diaBP']"
      ],
      "metadata": {
        "id": "xY6hpdIp12Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dded a column is_obese, where people with a BMI of 30 or more are marked as 1 (obese) and others as 0 (not obese).\n",
        "df['is_obese'] = (df['BMI'] >= 30).astype(int)"
      ],
      "metadata": {
        "id": "XiVEaI1934SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column 'high_cholesterol': 1 if total cholesterol > 240, else 0\n",
        "df['high_cholesterol'] = (df['totChol'] > 240).astype(int)"
      ],
      "metadata": {
        "id": "atUmyWVu4FYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 'glucose_status': normal, pre-diabetes, or diabetes based on glucose level\n",
        "df['glucose_status'] = df['glucose'].apply(lambda x: 'normal' if x < 100 else ('pre-diabetes' if x < 126 else 'diabetes'))"
      ],
      "metadata": {
        "id": "AXNDCNWw4jEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 'smoking_intensity' based on number of cigarettes per day\n",
        "# Non-smoker for 0 cigarettes,Light smoker for 1–10,Moderate smoker for 11–20,Heavy smoker for more than 20.\n",
        "df['smoking_intensity'] = pd.cut(df['cigsPerDay'], bins=[-1, 0, 10, 20, 60], labels=['non-smoker', 'light', 'moderate', 'heavy'])"
      ],
      "metadata": {
        "id": "gdYAj0ZV45PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head().T"
      ],
      "metadata": {
        "id": "yJgAFe6W21pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "columns=['age', 'education', 'cigsPerDay', 'BPMeds',\n",
        "        'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
        "        'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD', 'pulse_pressure',\n",
        "        'is_obese', 'smoking_intensity','high_cholesterol','glucose_status','smoking_intensity','sex']\n",
        "# let's create a function to check the outliers\n",
        "def check_outliers(columns,data):\n",
        "\n",
        "  # use plotly for better plot\n",
        "  for i in columns:\n",
        "    fig = px.box(data,y=i)\n",
        "    fig.update_layout(height=500, width=600)\n",
        "    fig.show()\n",
        "# Plot the graph\n",
        "check_outliers(columns,df)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "7X26gtodAbOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "vzlJ3B8HXRRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove row where 'smoking_intensity' is missing (NaN)\n",
        "df = df.dropna(subset=['smoking_intensity'])"
      ],
      "metadata": {
        "id": "xdXdRWLHpLWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s what I did with the data and what I found.:-\n",
        "1. In the cardiovascular dataset, the age of individuals ranged from 32 to 70 years.\n",
        "2. For **handling the null values**:-\n",
        "* **categorical columns** like education and BP medication, we filled missing values using the mode (the most frequent value).\n",
        "* **numerical columns** like cholesterol, BMI, glucose, and cigarettes per day, we filled missing values using the median.\n",
        "* Only **one row** had a missing heart rate, and since it's a crucial health indicator, we **dropped** that row from the dataset.\n",
        "3. A new column `pulse_pressure` was created by subtracting diastolic blood pressure (`diaBP`) from systolic blood pressure (`sysBP`). This helps understand the pressure difference during heartbeats.\n",
        "4. We added a column `is_obese`, where people with a BMI of 30 or more are marked as 1 (**obese**) and others as 0 (**not obese**).\n",
        "5. A column `high_cholesterol` was created. If someone’s total cholesterol is over 240, they are marked as 1 (**high**), else 0.\n",
        "6. Created a new column `glucose_status` to classify individuals based on their glucose levels:\n",
        "\n",
        "* **Normal** if glucose is below 100,\n",
        "\n",
        "* **Pre-diabetes** if between 100 and 125,\n",
        "\n",
        "* **Diabetes** if 126 or more.\n",
        "7. created a new column `smoking_intensity` to categorize individuals based on daily cigarette use:\n",
        "\n",
        "* **Non-smoker** for 0 cigarettes,\n",
        "\n",
        "* **Light smoker** for 1–10,\n",
        "\n",
        "* **Moderate smoker** for 11–20,\n",
        "\n",
        "* **Heavy smoker** for more than 20.\n",
        "8. `smoking_intensity` column had 1 NaN value,which can be dropped.\n",
        "9. After checking for outliers using boxplots, we found that `totChol`, `sysBP`, `diaBP`, `BMI`, `heartRate`, `glucose`, and `pulse_pressure` have the most outliers in the dataset,which needs to be removed for our modeling.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1: 10-Year CHD Risk by Age"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-Year CHD Risk by Age\n",
        "chd_by_age = df.groupby('age')['TenYearCHD'].mean()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(9, 5))\n",
        "chd_by_age.plot(kind='line', color='skyblue')\n",
        "plt.title('10-Year CHD Risk by Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('CHD Rate')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this line graph is being used:-\n",
        "* To show how the risk of developing Coronary Heart Disease (CHD) over 10 years changes with age.\n",
        "* A line chart is great for spotting trends over time or age, making it easy to see if risk increases, decreases, or stays the same as people get older.\n",
        "\n"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph:-\n",
        "* The chart clearly shows that the risk of CHD increases with age.\n",
        "\n",
        "* People in their 60s have a much higher risk, especially around ages 67–68.\n",
        "\n",
        "* After age 68 approx, there’s a sharp drop, which might be due to fewer people in that age group (less data).\n",
        "\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  <u>**Positive Business Impact:**</u>\n",
        "\n",
        "Yes, this chart can help the business grow in a good way.\n",
        "\n",
        "* **Focus on the Right Age Group**: It shows that people over **50**, especially between **60 and 70**, have a higher chance of heart disease. So, health companies can focus more on helping them.\n",
        "\n",
        "* **Offer Useful Health Plans**: Based on this, companies can create **special checkups, tips, and health plans** for older people to stay healthy.\n",
        "\n",
        "* **Spend Money Smartly**: Instead of spending randomly, companies can invest in the **right tools, services, or treatments** that help people at higher risk.\n",
        "\n",
        "* **Make Better Decisions**: This kind of data helps in **planning smartly** and offering better services.\n",
        "\n",
        "<u>**Negative Growth Risk:**</u>\n",
        "\n",
        "If this chart is not used correctly, it can cause problems:\n",
        "\n",
        "* **Don't Ignore People Over 70**: The risk looks lower after age 70, but that might be because there are **very few people** in that age group in the data — not because the risk actually drops.\n",
        "\n",
        "* **Wrong Decisions**: If someone looks at this chart and thinks older people aren’t at risk, they might make **bad business or health choices**.\n",
        "\n",
        "* **Missed Chances**: If companies don’t focus on the needs of older adults, they could **lose customers** and **damage their reputation**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2: 10-Year CHD Risk by Education Level"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-Year CHD Risk by Education Level\n",
        "# Calculate CHD rate by education level\n",
        "chd_by_edu = df.groupby('education')['TenYearCHD'].mean()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(7, 5))\n",
        "chd_by_edu.plot(kind='bar', color='mediumseagreen')\n",
        "plt.title('10-Year CHD Risk by Education Level')\n",
        "plt.xlabel('Education Level (1 = lowest, 4 = highest)')\n",
        "plt.ylabel('CHD Rate')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this,**Bar Graph** is being used as:-\n",
        "* It clearly shows the connection between education level and the risk of Coronary Heart Disease (CHD) over 10 years.\n",
        "* A bar graph is easy to read and helps us quickly compare how CHD risk changes with different education levels."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "\n",
        "1. People with the lowest education level (1) have the highest risk of developing CHD.\n",
        "\n",
        "2. As education level increases (from 1 to 4), the CHD risk generally goes down.\n",
        "\n",
        "3. However, level 4 (the highest) has a slightly higher risk than level 3 — this might need further checking.\n",
        "\n",
        "So overall, better education tends to be linked with better heart health as people get more aware about there health."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>**Positive Impact**</u>:\n",
        "1. Healthcare providers or insurance companies can use this insight to offer targeted awareness programs for people with lower education.\n",
        "\n",
        "2. Educational institutions or governments can focus on spreading basic health education in less-educated communities.\n",
        "\n",
        "3. It can also help prevent health issues early, which saves treatment costs in the long run.\n",
        "\n",
        "<u>**Negative Impact**</u>:\n",
        "* The unexpected rise in CHD risk for level 4 (highest education) compared to level 3 may confuse decision-makers or mislead policies if not investigated further.\n",
        "\n",
        "* This could result in misdirected efforts if we wrongly assume higher education always equals lower risk without considering other factors like stress, lifestyle, etc.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3: Distribution of CHD Cases by Sex"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of CHD Cases by Sex\n",
        "# Filter only CHD-positive cases\n",
        "chd_positive = df[df['TenYearCHD'] == 1]\n",
        "\n",
        "# Count how many males and females have CHD\n",
        "chd_by_sex = chd_positive['sex'].value_counts()\n",
        "\n",
        "# Map for better labels (optional)\n",
        "chd_by_sex.index = chd_by_sex.index.map({'M': 'Male', 'F': 'Female'})\n",
        "# Plot pie chart\n",
        "plt.figure(figsize=(8,5))\n",
        "colors = ['lightcoral', 'skyblue']\n",
        "plt.pie(chd_by_sex, labels=chd_by_sex.index, autopct='%1.1f%%', startangle=140, colors=colors, explode=(0.05, 0))\n",
        "plt.title('Distribution of CHD Cases by Sex')\n",
        "plt.axis('equal')  # Keeps the pie chart circular\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this,**Pie Chart** is used as:-\n",
        "* It gives a quick and clear picture of how heart disease (CHD) is spread between males and females.\n",
        "* A pie chart is perfect for comparing two groups and showing the percentage share of each."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "* 53.1% of the heart disease cases are in men\n",
        "\n",
        "* 46.9% are in women\n",
        "\n",
        "This tells us that men are slightly more affected than women, but the gap is not huge. So, both genders are at risk, and health programs should focus on both."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Positive Impact</u>**:\n",
        "1. Better Targeting: Knowing that both men and women are affected, they can create health awareness campaigns for both — not just for one gender.\n",
        "\n",
        "2. Balanced Services: Companies can design equal health checkups, plans, or diets for both men and women to prevent CHD.\n",
        "\n",
        "3. rust Building: When people see companies focusing on both genders, it builds trust and shows fairness — which can lead to more customers and better reputation.\n",
        "**<u>Negative Growth Risk:</u>**\n",
        "1. Assuming only men are at risk (just because it’s 53.1%) might cause female health needs to be ignored, which would be a big mistake.\n",
        "\n",
        "2. If companies don’t look deeper into why the difference exists, they might miss important factors like lifestyle, stress, or access to care — and that can hurt future planning.\n"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4: CHD Rate by Smoking Status"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHD Rate by Smoking Status\n",
        "# Calculate CHD rate by smoking status\n",
        "chd_by_smoking = df.groupby('is_smoking')['TenYearCHD'].mean()\n",
        "\n",
        "# Fix labels if they're YES/NO strings\n",
        "chd_by_smoking.index = chd_by_smoking.index.map({'YES': 'Smoker', 'NO': 'Non-Smoker'})\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "chd_by_smoking.plot(kind='bar', color='salmon')\n",
        "plt.title('CHD Rate by Smoking Status')\n",
        "plt.xlabel('Smoking Status')\n",
        "plt.ylabel('CHD Rate')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this,**Bar Graph**is being used:-\n",
        "* It makes it easy to compare the chances of getting heart disease (CHD) between smokers and non-smokers.\n",
        "* It’s a clear way to see how smoking affects heart health, and it quickly grabs attention."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "* Smokers have a higher CHD rate (around 16%)\n",
        "\n",
        "* Non-smokers have a lower CHD rate (around 14%)\n",
        "\n",
        "This means that smoking increases the risk of heart disease. Even though the difference looks small, it’s important and real — smoking clearly adds to the risk."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Positive Growth:</u>**\n",
        "1. Design No-Smoking Programs: Health companies can offer special plans or rewards for people who quit smoking or want to reduce it.\n",
        "\n",
        "2. Targeted Messaging: This data can help in creating awareness campaigns to show how smoking increases heart disease risk, which might encourage people to stop.\n",
        "\n",
        "3. Lower Costs: Helping people stop smoking can reduce future health issues, which means lower treatment costs for companies and insurers.\n",
        "**<u>Negative Growth :</u>**\n",
        "1. The difference in risk might look small, so some may ignore it or not take it seriously, leading to poor decisions.\n",
        "\n",
        "2. If companies focus only on smokers, they might forget that non-smokers also get CHD, though less — which can cause missed opportunities for broader health promotion."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5: 10-Year CHD Risk by Smoking Intensity"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-Year CHD Risk by Smoking Intensity\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Temporarily define smoking intensity categories\n",
        "def classify_smoking(cigs):\n",
        "    if cigs == 0:\n",
        "        return 'Non-smoker'\n",
        "    elif cigs <= 10:\n",
        "        return 'Light'\n",
        "    elif cigs <= 20:\n",
        "        return 'Moderate'\n",
        "    else:\n",
        "        return 'Heavy'\n",
        "\n",
        "# Apply categorization (no column created in df)\n",
        "df_temp = df.copy()\n",
        "df_temp['smoking_intensity'] = df_temp['cigsPerDay'].apply(classify_smoking)\n",
        "\n",
        "# Group and calculate CHD rate\n",
        "chd_by_intensity = df_temp.groupby('smoking_intensity')['TenYearCHD'].mean().reindex(['Non-smoker', 'Light', 'Moderate', 'Heavy'])\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(7, 5))\n",
        "chd_by_intensity.plot(kind='bar', color='darkorange')\n",
        "plt.title('10-Year CHD Risk by Smoking Intensity')\n",
        "plt.xlabel('Smoking Intensity')\n",
        "plt.ylabel('CHD Rate')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this,**Bar Graph** is being used as:-\n",
        "* It shows not just whether someone smokes, but how much they smoke — and how that affects their risk of heart disease over 10 years.\n",
        "* It's a simple and visual way to understand how smoking intensity (light, moderate, heavy) increases health risks step-by-step."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "* Light smokers have a slightly lower risk than non-smokers (possibly due to data imbalance or behavior patterns).\n",
        "\n",
        "* Moderate smokers show higher CHD risk.\n",
        "\n",
        "* Heavy smokers have the highest risk of heart disease.\n",
        "\n",
        "This means: the more someone smokes, the greater their chance of getting CHD. Even light smoking isn’t risk-free."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>**Positive Impact**</u>:\n",
        "1. Create Step-Based Quit Plans: Businesses can design personalized health plans to help people reduce smoking intensity gradually — from heavy to moderate, and then quit.\n",
        "\n",
        "2. Raise Awareness: This chart can be used in campaigns to clearly show the dangers of heavy smoking, which may motivate people to take action.\n",
        "\n",
        "3. Smarter Health Investment: Healthcare companies can focus more support on heavy/moderate smokers, where the risk is highest, saving costs in long-term treatment.\n",
        "<u>**Negative Impact**</u>:\n",
        "1. Seeing that light smokers have lower risk than non-smokers might give a false idea that light smoking is safe — which is dangerous and misleading.\n",
        "\n",
        "2. If companies only focus on heavy smokers, they might miss early-stage smokers who still need help — leading to missed prevention opportunities.\n",
        "\n"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6: CHD Rate by Stroke and Hypertension History"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Step 1: Group and calculate mean CHD rate\n",
        "grouped = df.groupby(['prevalentStroke', 'prevalentHyp'])['TenYearCHD'].mean().reset_index()\n",
        "\n",
        "# Step 2: Convert binary values to readable labels (optional)\n",
        "grouped['prevalentStroke'] = grouped['prevalentStroke'].map({0: 'No Stroke', 1: 'Stroke'})\n",
        "grouped['prevalentHyp'] = grouped['prevalentHyp'].map({0: 'No Hypertension', 1: 'Hypertension'})\n",
        "\n",
        "# Step 3: Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=grouped, x='prevalentHyp', y='TenYearCHD', hue='prevalentStroke', palette='Set2')\n",
        "\n",
        "plt.title('CHD Rate by Stroke and Hypertension History')\n",
        "plt.xlabel('Hypertension Status')\n",
        "plt.ylabel('CHD Rate')\n",
        "plt.legend(title='Stroke Status')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this,**Double Bar Graph** is being used as:-\n",
        "* It shows how stroke and high blood pressure (hypertension) together affect the chances of getting Coronary Heart Disease (CHD).\n",
        "* It clearly breaks the risk down into 4 groups, making it easy to compare and understand."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "* People with no blood pressure problem and no stroke have the lowest chance of getting heart disease.\n",
        "\n",
        "* If someone has either stroke or high BP, their chance of heart disease goes up.\n",
        "\n",
        "* But if someone has both stroke and high BP, their chance of heart disease becomes very high — more than 50%.\n",
        "\n",
        "Having either stroke or high BP increases your heart disease risk. But having both increases the risk a lot more."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Positive Impact</u>**:\n",
        "1. Better Targeting: Hospitals or health apps can target people with both stroke and hypertension history for urgent care and monitoring.\n",
        "\n",
        "2. Preventive Plans: This chart highlights high-risk groups, helping health providers offer custom preventive programs (like BP control, stroke recovery, etc.).\n",
        "\n",
        "3. Insurance Guidance: Insurance companies can use this to assess risk better and offer appropriate health coverage or premium adjustments.\n",
        "\n",
        "<u>**Negative Impact</u>**:\n",
        "1. If people only have one issue (stroke or hypertension), they might wrongly assume they are safe. But their risk is still higher than average.\n",
        "\n",
        "2. Some may panic seeing high risk and avoid checkups, thinking it’s already too late — which prevents early intervention.\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7: CHD Rate by Glucose Status and BP Medication"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHD Rate by Glucose Status and BP Medication\n",
        "# Step 1: Group and calculate CHD rate by glucose_status and BPMeds\n",
        "grouped = df.groupby(['glucose_status', 'BPMeds'])['TenYearCHD'].mean().unstack(fill_value=0)\n",
        "\n",
        "# Step 2: Plot stacked bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "grouped.plot(kind='bar', stacked=True, color=['lightgreen', 'coral'])\n",
        "\n",
        "plt.title('Stacked CHD Rate by Glucose Status and BP Medication')\n",
        "plt.xlabel('Glucose Status')\n",
        "plt.ylabel('CHD Rate')\n",
        "plt.legend(title='On BP Meds?', labels=['No', 'Yes'])\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this,**Stacked Bar Chart** is being used as:-\n",
        "* It clearly shows how blood sugar levels (glucose status) and whether someone is taking blood pressure (BP) medication affect the risk of getting Coronary Heart Disease (CHD).\n",
        "* The use of stacked bars helps compare both factors at once — making the combined risk very easy to understand."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "* People with diabetes have the highest CHD rate, especially those on BP medication.\n",
        "\n",
        "* People with normal or pre-diabetic sugar levels have a lower risk, but that risk still rises if they are on BP meds.\n",
        "\n",
        "* Being on BP meds seems to increase CHD risk across all glucose levels.\n",
        "\n",
        "If you have high blood sugar (especially diabetes) and you're on blood pressure medicine, your heart disease risk is much higher."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Positive Impact</u>**:\n",
        "\n",
        "1. Healthcare Focus: Hospitals can monitor people with both diabetes and high BP more closely to prevent heart disease.\n",
        "\n",
        "2. Early Warnings: Health apps and devices can use this insight to alert at-risk users before it's too late.\n",
        "\n",
        "3. Insurance Benefits: Insurance companies can use this to adjust coverage and promote preventive care plans for high-risk groups.\n",
        "\n",
        "**<u>Negative Impact</u>**:\n",
        "* People who are only on BP meds or only diabetic may think they’re completely safe — but their risk is still elevated.\n",
        "\n",
        "* Some might think BP medication causes heart disease, which is not true — it signals that BP is already high, which increases risk.\n",
        "\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8: Obesity Distribution in the Dataset"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obesity Distribution in the Dataset\n",
        "obese_counts = df['is_obese'].value_counts()\n",
        "\n",
        "# Step 2: Create a donut chart (a pie chart with a hole in the middle)\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.pie(obese_counts, labels=['Non-obese', 'Obese'], autopct='%1.1f%%', startangle=90,\n",
        "        colors=['lightblue', 'salmon'], wedgeprops={'width': 0.3, 'edgecolor': 'white'})\n",
        "\n",
        "# Step 3: Add a title\n",
        "plt.title('Obesity Distribution in the Dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this,**Donut Chart** is being used as:-\n",
        "* It’s a very clear and visual way to show proportions.\n",
        "Instead of looking at raw numbers, you can instantly see what percentage of people are obese vs. non‑obese.\n",
        "* The color difference (red for obese and blue for non‑obese) makes it easy to understand at a glance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "\n",
        "* 87.1% of the people in the dataset are non‑obese.\n",
        "\n",
        "* 12.9% are obese.\n",
        "\n",
        "Most of the people in the dataset are not obese, and only a small portion (around 13%) are obese."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<u>**Positive Impact:**</u>\n",
        "\n",
        "* **Targeted Programs:** Healthcare and fitness companies can design special plans, diet programs, or fitness routines specifically for the 12.9% obese group.\n",
        "* **Focused Campaigns:** Awareness drives can be tailored to encourage healthier lifestyles and preventive care for those at higher risk.\n",
        "* **Market Opportunities:** Businesses can develop new products or services (like weight management apps, health supplements, or coaching) targeted at this specific segment.\n",
        "\n",
        "\n",
        "\n",
        "<u>**Negative Impact:**</u>\n",
        "\n",
        "* **Misinterpretation Risk:** Some might wrongly assume that because only 12.9% are obese, obesity isn’t a major concern — but even a small percentage can lead to significant healthcare costs and risks.\n",
        "* **Overlooking Other Factors:** Focusing too much on obesity might make people ignore other health risks (like poor diet or inactivity) among the 87.1% non‑obese group.\n",
        "\n"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9: CHD Rate by Cholesterol Level"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHD Rate by Cholesterol Level\n",
        "grouped_chol = df.groupby(['high_cholesterol'])['TenYearCHD'].mean().reset_index()\n",
        "\n",
        "# Optional: Rename values for better readability\n",
        "grouped_chol['high_cholesterol'] = grouped_chol['high_cholesterol'].map({0: 'Normal Chol', 1: 'High Chol'})\n",
        "\n",
        "# Plot simple bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=grouped_chol, x='high_cholesterol', y='TenYearCHD', palette='Set2')\n",
        "\n",
        "plt.title('CHD Rate by Cholesterol Level')\n",
        "plt.xlabel('Cholesterol Level')\n",
        "plt.ylabel('CHD Rate')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this,**Bar Graph** is being used:-\n",
        "* It clearly shows the relationship between cholesterol levels (normal vs. high) and the rate of CHD (heart disease).\n",
        "* It’s easy to read and directly compares just two categories without extra complexity.\n",
        "\n"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "1. People with high cholesterol have a higher CHD rate (about 18%) than those with normal cholesterol (about 12.5%).\n",
        "\n",
        "2. This shows that cholesterol level alone has a strong influence on the likelihood of heart disease.\n",
        "\n"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<u>**Positive Impact:**</u>\n",
        "\n",
        "* **Healthcare Focus:** Hospitals or clinics can prioritize cholesterol management programs to prevent heart disease.\n",
        "* **Early Warnings:** Health apps can notify users to get regular cholesterol checks and adopt healthier habits.\n",
        "* **Insurance Benefits:** Insurance companies can design plans with incentives for maintaining healthy cholesterol levels.\n",
        "\n",
        "<u>**Negative Impact:**</u>\n",
        "\n",
        "* **False Sense of Security:** Someone with “normal” cholesterol might assume they’re completely safe and ignore other risks like smoking or high blood pressure.\n",
        "* **Overemphasis on Cholesterol Alone:** Businesses might wrongly focus only on cholesterol, forgetting other important factors that also contribute to CHD.\n",
        "\n"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10: Pulse Pressure Distribution by CHD Status"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pulse Pressure Distribution by CHD Status\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.boxplot(data=df, x='TenYearCHD', y='pulse_pressure', palette='Set2')\n",
        "\n",
        "plt.title('Pulse Pressure Distribution by CHD Status')\n",
        "plt.xlabel('CHD (0 = No, 1 = Yes)')\n",
        "plt.ylabel('Pulse Pressure (mm Hg)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a boxplot because it clearly shows the distribution of pulse pressure for two groups:\n",
        "\n",
        "* People without CHD (0)\n",
        "\n",
        "* People with CHD (1)\n",
        "\n",
        "It highlights medians, spreads, and outliers in both groups, which is useful for comparing variability and central tendency."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "* Median pulse pressure is higher in people with CHD compared to those without CHD.\n",
        "\n",
        "* People with CHD also show more variability (wider interquartile range) and more extreme outliers (some values above 140 mm Hg).\n",
        "\n",
        "This suggests a trend that higher pulse pressure may be associated with increased CHD risk.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<u>**Positive Impact:**</u>\n",
        "\n",
        "* **Healthcare Monitoring:** Hospitals or clinics can monitor pulse pressure as an early indicator for CHD risk and design targeted interventions.\n",
        "* **Wearable Devices:** Fitness/health devices can track pulse pressure and alert users when values reach risky levels.\n",
        "* **Insurance/Preventive Programs:** Insurance companies can use pulse pressure trends to encourage preventive care plans.\n",
        "\n",
        "<u>**Negative Impact:**</u>\n",
        "\n",
        "* **False Security for Normal Readings:** People with normal pulse pressure might think they are fully safe, while other risk factors (cholesterol, diabetes, etc.) could still be present.\n",
        "* **Misinterpretation of Outliers:** Some might wrongly think that a single high reading means CHD, while clinical context is needed.\n"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ec9xy7KWWXl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your dataset\n",
        "# df = pd.read_csv(\"your_file.csv\")  # Uncomment and load your CSV if needed\n",
        "\n",
        "# List of columns to use (excluding 'id')\n",
        "cols = ['age', 'education', 'cigsPerDay', 'BPMeds',\n",
        "        'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
        "        'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD', 'pulse_pressure',\n",
        "        'is_obese', 'smoking_intensity']\n",
        "\n",
        "# Create a copy of relevant data\n",
        "df_corr = df[cols].copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Map smoking_intensity: non-smoker → 0, light → 1, moderate → 2, heavy → 3\n",
        "df_corr['smoking_intensity'] = df['smoking_intensity'].map({\n",
        "    'non-smoker': 0,\n",
        "    'light': 1,\n",
        "    'moderate': 2,\n",
        "    'heavy': 3\n",
        "})\n",
        "\n",
        "# Convert entire DataFrame to numeric, coerce errors\n",
        "df_corr = df_corr.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Fill any remaining NaNs with median values\n",
        "df_corr = df_corr.fillna(df_corr.median())\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = df_corr.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True,\n",
        "            cbar_kws={\"shrink\": 0.8}, linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\", fontsize=18)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "I chose a **correlation heatmap** because:\n",
        "\n",
        "* It visually shows the relationships between many variables at once.\n",
        "* It highlights both positive and negative correlations using color intensity (red = strong positive, blue = negative).\n",
        "* It’s ideal for quickly identifying which features are strongly related, which is important before building predictive models or doing feature selection.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some key correlations observed:\n",
        "\n",
        "* **Strong positive correlations:**\n",
        "\n",
        "  * `cigsPerDay` and `smoking_intensity` (0.96): unsurprising, as they measure similar behavior.\n",
        "  * `sysBP` and `diaBP` (0.78): systolic and diastolic blood pressure rise together.\n",
        "  * `sysBP` and `pulse_pressure` (0.86): higher systolic values strongly influence pulse pressure.\n",
        "  * `BMI` and `is_obese` (0.70): higher BMI is strongly associated with obesity status.\n",
        "* **Moderate correlations:**\n",
        "\n",
        "  * `diabetes` and `glucose` (0.61): expected medical relationship.\n",
        "  * `prevalentHyp` and `sysBP` (0.70): hypertension aligns with higher systolic blood pressure.\n",
        "* **Low correlations:**\n",
        "\n",
        "  * `TenYearCHD` (target variable) shows only weak correlations with individual factors (e.g., age 0.22, sysBP 0.14).CHD likely depends on **multiple factors combined**, not a single dominant variable."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pair Plot\n",
        "cols_to_plot = [\n",
        "    'age', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP',\n",
        "    'BMI', 'glucose', 'pulse_pressure', 'TenYearCHD'\n",
        "]\n",
        "\n",
        "# Pair plot\n",
        "sns.pairplot(df[cols_to_plot], hue='TenYearCHD', palette='Set2', diag_kind='kde')\n",
        "\n",
        "plt.suptitle('Pair Plot of Selected Features Colored by CHD Status', y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a pair plot because it quickly shows how many variables relate to each other at once—each diagonal shows a variable’s spread, and the scatterplots show relationships between pairs, helping spot patterns easily."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be made from the graph are:-\n",
        "\n",
        "* People with CHD (heart disease) tend to be older and have higher blood pressure and pulse pressure compared to those without CHD.\n",
        "* Some features are related to each other — for example, systolic and diastolic blood pressure go up together.\n",
        "* However, there’s still a lot of overlap between the CHD and non-CHD groups, meaning no single feature perfectly separates them.\n",
        "\n"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset does not contain any null values now."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtered rows to include only total cholesterol values between 119 and 350, removing unrealistic extremes.\n",
        "df = df[(df['totChol'] <= 350) & (df['totChol'] >= 119)]"
      ],
      "metadata": {
        "id": "M8KF32gwpcQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capped extreme values in health measures (e.g., BP, BMI, heart rate, etc.) using the IQR method to reduce outlier impact.\n",
        "def cap_outliers(series):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return series.clip(lower=lower_bound, upper=upper_bound)"
      ],
      "metadata": {
        "id": "LwqM17hJphHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sysBP'] = cap_outliers(df['sysBP'])\n",
        "df['diaBP'] = cap_outliers(df['diaBP'])"
      ],
      "metadata": {
        "id": "ZG6alYPppkeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['BMI'] = cap_outliers(df['BMI'])"
      ],
      "metadata": {
        "id": "ChL9NexHgoI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['heartRate'] = cap_outliers(df['heartRate'])"
      ],
      "metadata": {
        "id": "cxqgC0YCgsH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['pulse_pressure'] = cap_outliers(df['pulse_pressure'])"
      ],
      "metadata": {
        "id": "_WHhhIqdgyyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['glucose'] = cap_outliers(df['glucose'])"
      ],
      "metadata": {
        "id": "luoN22gohZ1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_outliers(columns,df)"
      ],
      "metadata": {
        "id": "bfoIZbJSg3nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**The Outlier Techniques that I used are:-**\n",
        "\n",
        " **Removed cholesterol values that are unrealistic**\n",
        "I only kept total cholesterol between 119 and 350, because anything outside this range is likely a mistake or abnormal.\n",
        "\n",
        " **Capped extreme values in health measures**\n",
        "For columns like blood pressure, BMI, heart rate, pulse pressure, and glucose, I limited very high or very low values to a reasonable range so that extreme points don’t affect the analysis too much.\n",
        "\n",
        "**Used IQR method for capping**\n",
        "I used the 25th and 75th percentiles (IQR method) to detect and cap outliers, so data becomes cleaner and easier for the model to work with.\n"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Label Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "new_df = df.copy()\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for col in new_df.columns:\n",
        "    if new_df[col].dtype == 'object' or str(new_df[col].dtype) == 'category':\n",
        "        new_df[col] = label_encoder.fit_transform(new_df[col].astype(str)).astype('int')\n",
        "\n",
        "# Replace the original df with the new one\n",
        "df = new_df"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The categorical encoding I have used is **Label Encoding method**\n",
        "\n",
        "I have used this method because:-\n",
        "\n",
        "* Some columns in the data had text values (like “Male”/“Female” or “Yes”/“No”).\n",
        "* Machine learning models can’t work directly with text — they need numbers.\n",
        "* **Label Encoding** simply changes each unique text into a unique number (for example: “Male” → 0, “Female” → 1).\n",
        "\n",
        "I used this because it’s simple, fast, and works well when the text values don’t have any special order (just categories).\n"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check target classes balance\n",
        "cla_bal = df['TenYearCHD'].value_counts(normalize=True)\n",
        "print(cla_bal)\n",
        "\n",
        "# Plot the classes\n",
        "cla_bal.plot(kind = 'bar')\n",
        "plt.title('NotRisk(0) and Risk(1) comparison',fontweight = \"bold\")\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Percentage')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z9k9o2llruKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#renaming label column\n",
        "df['IsatRisk'] =df ['TenYearCHD']\n",
        "df.drop('TenYearCHD',axis = 1)"
      ],
      "metadata": {
        "id": "iOPv7M1qsJNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_smote, y_smote = smote.fit_resample(df.iloc[:,0:-1], df['IsatRisk'])\n",
        "\n",
        "# Print the actual data and resampled data\n",
        "print('Original dataset shape', len(df))\n",
        "print('Resampled dataset shape', len(y_smote))"
      ],
      "metadata": {
        "id": "IxkHCATSsCLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The dataset is more biased toward 0 (no CHD), since about 85% of the records are 0 and only about 15% are 1 (yes CHD).\n",
        "* This means the data is imbalanced, which could affect model performance by making it favor predicting class 0 more often."
      ],
      "metadata": {
        "id": "rmwY4GFNVdU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used **SMOTE Technique** for the handling of imbalaced daatset:-\n",
        "* SMOTE helps fix this by creating new, similar samples for the smaller class (at risk) instead of just copying them.\n",
        "* This makes both classes more balanced, so the model can learn to detect the minority class better and not just favor the majority class."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the list of all column name\n",
        "columns = list(df.columns)\n",
        "columns"
      ],
      "metadata": {
        "id": "cy1h3xgSsdbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns.pop()"
      ],
      "metadata": {
        "id": "ZJkGFrG1sigF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns.remove('TenYearCHD')"
      ],
      "metadata": {
        "id": "3GYVM4wFskuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Created a new DataFrame from the SMOTE-balanced feature set with the original column names.\n",
        "balance_df = pd.DataFrame(x_smote, columns=columns)"
      ],
      "metadata": {
        "id": "yU9KMj3ZsnTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Added the target variable 'IsatRisk' to balance_df from the SMOTE-balanced labels.\n",
        "balance_df['IsatRisk'] = y_smote"
      ],
      "metadata": {
        "id": "X-m36IMmsqbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created a copy of balance_df as df_fr to preserve the original balanced data.\n",
        "df_fr = balance_df.copy()"
      ],
      "metadata": {
        "id": "MqV73f32ss55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr.columns"
      ],
      "metadata": {
        "id": "jERxmK0jsvv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapped numeric values in categorical columns to descriptive labels (e.g., sex, smoking details, glucose status) for clarity.\n",
        "df_fr.replace({\n",
        "    'sex': {1: 'male', 0: 'female'},\n",
        "    'is_smoking': {1: 'yes', 0: 'no'},\n",
        "    'smoking_intensity': {\n",
        "        0: 'Heavy Smoker',       # numeric to label\n",
        "        1: 'Light Smoker',\n",
        "        2: 'Moderate Smoker',\n",
        "        3: 'Non-Smoker'\n",
        "    },\n",
        "    'glucose_status': {\n",
        "        0: 'Pre-diabetes',           # numeric to label\n",
        "        1: 'Normal',\n",
        "        2: 'Diabetes'\n",
        "    }\n",
        "}, inplace=True)\n"
      ],
      "metadata": {
        "id": "Fw439Rurupng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr.head()"
      ],
      "metadata": {
        "id": "gugFJ7-vuszj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical Encoding"
      ],
      "metadata": {
        "id": "ecMizYIDvWPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr.info()"
      ],
      "metadata": {
        "id": "KP79SsR6vVlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr = pd.get_dummies(df_fr,columns=['sex','is_smoking','glucose_status','smoking_intensity'])"
      ],
      "metadata": {
        "id": "cowwXw-LwPC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fr.head()"
      ],
      "metadata": {
        "id": "sfebv2TGwSZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used pd.get_dummies() to convert the textual data in the value that can be understand by our model easily."
      ],
      "metadata": {
        "id": "KwzsiHXpXFZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping of id column as it is unique\n",
        "df_fr.drop('id',axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "RxsHngkIwX0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crezted a copy of df_fr as df_log_reg to preserve the data\n",
        "df_log_reg = df_fr.copy()"
      ],
      "metadata": {
        "id": "cWi1iudfxHkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defined X as all feature columns (excluding 'IsatRisk') and y as the target column 'IsatRisk'.\n",
        "X = df_log_reg.drop('IsatRisk', axis=1)  # Features\n",
        "y = df_log_reg['IsatRisk']  # Target variable"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saved all feature column names from X into the variable 'columns'.\n",
        "columns = X.columns"
      ],
      "metadata": {
        "id": "GFwKTf09xMYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I **removed columns** that are not useful or may cause overfitting, like:\n",
        "\n",
        "  * `'isAtRisk'` — this is the target, so we removed it from features.\n",
        "\n",
        "> This method is called **manual feature selection** based on logic, correlation, and avoiding repeated or unhelpful data."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features that are imp are:-\n",
        "* **Age** –\n",
        "  Older people showed a higher chance of CHD, so age is an important risk factor.\n",
        "\n",
        "* **Systolic Blood Pressure (sysBP)** –\n",
        "  Higher blood pressure was linked to more CHD cases, making it a key feature.\n",
        "\n",
        "* **Diastolic Blood Pressure (diaBP)** –\n",
        "  Often goes hand in hand with systolic, and high values increase heart risk.\n",
        "\n",
        "* **Pulse Pressure** –\n",
        "  A larger difference between systolic and diastolic pressures often signals heart issues.\n",
        "\n",
        "* **Total Cholesterol (totChol)** –\n",
        "  High cholesterol levels were commonly seen in people with CHD.\n",
        "\n",
        "* **BMI / Obesity status** –\n",
        "  Higher BMI and obesity contribute to heart strain and higher CHD risk.\n",
        "\n",
        "* **Glucose / Diabetes** –\n",
        "  People with high glucose or diabetes showed higher CHD rates.\n",
        "\n",
        "* **Smoking‑related features (like cigsPerDay)** –\n",
        "  Smoking is a known heart risk, and heavier smokers showed more CHD."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use standard scaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I used **StandardScaler** to scale the data.\n",
        "* It changes the values so that each feature has **mean = 0** and **standard deviation = 1**.\n",
        "* This helps the model learn better and faster because all features are on a **similar scale**.\n",
        "* It's especially useful when features have **different units** or **ranges**.\n"
      ],
      "metadata": {
        "id": "xLAc5WS5YqKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets (33% test) while keeping CHD class balance using stratify..\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I used a **67:33 split** — 67% of the data for training and 33% for testing.\n",
        "* This allows the model to learn from most of the data (67%) while still keeping enough data (33%) to evaluate its performance on unseen data.\n",
        "* It’s a **balanced choice** — giving a good trade‑off between training and testing accuracy.\n"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1: Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_regression = LogisticRegression(random_state=42)\n",
        "logistic_regression.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = logistic_regression.predict(X_train)\n",
        "y_test_pred = logistic_regression.predict(X_test)"
      ],
      "metadata": {
        "id": "WZf0NsT0yFmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing important matrices\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix"
      ],
      "metadata": {
        "id": "hSLayBgByI1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing accuracy\n",
        "train_accuracy1 = accuracy_score(y_train_pred, y_train)\n",
        "test_accuracy1 = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('Training accuracy:', train_accuracy1)\n",
        "print('Testing accuracy:', test_accuracy1)"
      ],
      "metadata": {
        "id": "Z_KkYUCVyNT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get scores like precision,recall, f1 score,roc_auc_score, confusion matrix\n",
        "  # precision,\n",
        "log_test_precision1 = precision_score(y_test,y_test_pred)\n",
        "\n",
        "  # recall,\n",
        "log_test_recall1 = recall_score(y_test,y_test_pred,)\n",
        "\n",
        "  # f1 score\n",
        "log_f1_score1 = f1_score(y_test,y_test_pred)\n",
        "\n",
        "  # roc_auc_score\n",
        "log_roc_auc_score1 = roc_auc_score(y_test,y_test_pred)\n",
        "\n",
        "  # confusion matrix\n",
        "log_confusion_mat = confusion_matrix(y_test,y_test_pred)\n",
        "\n",
        "  # Printing all these matrices\n",
        "print('Precision score of logistic model:',log_test_precision1)\n",
        "print(' ')\n",
        "print('Recall score of logistic model:', log_test_recall1)\n",
        "print(' ')\n",
        "print('F1 score of logistic model: ', log_f1_score1)\n",
        "print(' ')\n",
        "print('ROC AUC score of logistic model: ',log_roc_auc_score1)\n",
        "print(' ')\n",
        "print('Confusion matrix of logistic model \\n:',log_confusion_mat)\n",
        "print(' ')\n",
        "labels = ['Not At Risk','At Risk']\n",
        "\n",
        "# plotting confusion matrix through heatmap\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(log_confusion_mat,cmap = 'Greens', annot = True, xticklabels = labels, yticklabels = labels)\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predcted Class')\n",
        "plt.title('Confusion Matrix of Logistic Model',fontsize = 12)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "**Model Used:**\n",
        "\n",
        "* I used a **Logistic Regression model**.\n",
        "Logistic Regression is a simple and effective algorithm for predicting binary outcomes — in this case, whether someone will develop CHD (1) or not (0).\n",
        "* It works by finding patterns in the input features to estimate the probability of a positive outcome.\n",
        "\n",
        "\n",
        "**Model Performance:**\n",
        "\n",
        "* **Training Accuracy:** 77.70%\n",
        "\n",
        "* **Testing Accuracy:** 76.62%\n",
        "  *The model performs similarly on training and testing data, which means it generalizes fairly well without heavy overfitting.*\n",
        "\n",
        "* **Precision:** 80.05%\n",
        "  *When the model predicts someone will have CHD, it is correct 80% of the time.*\n",
        "\n",
        "* **Recall:** 70.93%\n",
        "  *Out of all people who actually have CHD, the model correctly identifies about 71% of them.*\n",
        "\n",
        "* **F1 Score:** 75.21%\n",
        "  *This shows a good balance between precision and recall.*\n",
        "\n",
        "* **ROC AUC Score:** 76.62%\n",
        "  *The model can distinguish between CHD and non‑CHD cases about 76% of the time.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The **Logistic Regression model** is performing reasonably well with a testing accuracy of around 76%.\n",
        "\n",
        "It is fairly precise when predicting CHD and captures most actual CHD cases, making it a reliable and interpretable choice for this dataset.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XFJOE497j4jP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "jaTCqy0Vybbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting the model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "logistic_regression = LogisticRegression(random_state=42)\n",
        "param_grid = {'penalty':['l1','l2'], 'C' : [0.0001,0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 10] }   #set the parmeter\n",
        "\n",
        "logistic_grid_model= GridSearchCV(logistic_regression, param_grid, scoring = 'precision',n_jobs = -1, verbose = 3, cv = 3)\n",
        "logistic_grid_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best score\n",
        "logistic_grid_model.best_score_"
      ],
      "metadata": {
        "id": "ZTeHZEF2yp8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = logistic_grid_model.predict(X_train)\n",
        "y_test_pred = logistic_grid_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Czaq51yaytHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing important matrices\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix"
      ],
      "metadata": {
        "id": "AhyervV-y1F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing accuracy\n",
        "train_accuracy1 = accuracy_score(y_train_pred, y_train)\n",
        "test_accuracy1 = accuracy_score(y_test_pred,y_test)\n",
        "\n",
        "print('Training accuracy:', train_accuracy1)\n",
        "print('Testing accuracy:', test_accuracy1)"
      ],
      "metadata": {
        "id": "tDG3yzI4y4q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get scores like precision,recall, f1 score,roc_auc_score, confusion matrix\n",
        "  # precision,\n",
        "log_test_precision1_cv= precision_score(y_test,y_test_pred)\n",
        "\n",
        "  # recall,\n",
        "log_test_recall1_cv= recall_score(y_test,y_test_pred,)\n",
        "\n",
        "  # f1 score\n",
        "log_f1_score1_cv= f1_score(y_test,y_test_pred)\n",
        "\n",
        "  # roc_auc_score\n",
        "log_roc_auc_score1_cv= roc_auc_score(y_test,y_test_pred)\n",
        "\n",
        "  # confusion matrix\n",
        "log_confusion_mat_cv= confusion_matrix(y_test,y_test_pred)\n",
        "\n",
        "  # Printing all these matrices\n",
        "print('Precision score of logistic model:',log_test_precision1_cv)\n",
        "print(' ')\n",
        "print('Recall score of logistic model:', log_test_recall1_cv)\n",
        "print(' ')\n",
        "print('F1 score of logistic model: ', log_f1_score1_cv)\n",
        "print(' ')\n",
        "print('ROC AUC score of logistic model: ',log_roc_auc_score1_cv)\n",
        "print(' ')\n",
        "print('Confusion matrix of logistic model \\n:',log_confusion_mat_cv)\n",
        "print(' ')\n",
        "labels = ['Not At Risk','At Risk']\n",
        "\n",
        "# plotting confusion matrix through heatmap\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(log_confusion_mat,cmap = 'Greens', annot = True, xticklabels = labels, yticklabels = labels)\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predcted Class')\n",
        "plt.title('Confusion Matrix of Logistic Model',fontsize = 12)"
      ],
      "metadata": {
        "id": "7KL2lDkGy-pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Model Used:**\n",
        "I used **Logistic Regression with GridSearchCV**.\n",
        "GridSearchCV helps to automatically search for the best hyperparameters for Logistic Regression by testing different combinations and picking the one that gives the best performance.\n",
        "Logistic Regression itself is a popular algorithm for predicting binary outcomes — here, whether a person will develop CHD (1) or not (0).\n",
        "\n"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Model Performance:**\n",
        "\n",
        "* **Training Accuracy:** ~77%\n",
        "\n",
        "* **Testing Accuracy:** ~77%\n",
        "  *The model performs almost the same on training and testing data, which shows it is generalizing well and not overfitting.*\n",
        "\n",
        "* **Precision:** ~80%\n",
        "  *When the model predicts someone will have CHD, it is correct 81% of the time.*\n",
        "\n",
        "* **Recall:** ~70%\n",
        "  *Out of all people who actually have CHD, the model correctly identifies about 70% of them.*\n",
        "\n",
        "* **F1 Score:** ~75%\n",
        "  *A balanced measure combining both precision and recall.*\n",
        "\n",
        "* **ROC AUC Score:** ~77%\n",
        "  *The model can distinguish between CHD and non‑CHD cases 78% of the time.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The **Logistic Regression model tuned with GridSearchCV** is performing well.\n",
        "\n",
        "It predicts CHD outcomes with good accuracy (~77%), strong precision ( ~80%), and model is fairly accurate with high precision but moderate recall.\n",
        "\n"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2: Random Forest Classifier"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators = 5,random_state=42)\n",
        "rf_classifier.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "w-dBneAu23ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class predictions\n",
        "y_train_rf_pred = rf_classifier.predict(X_train)\n",
        "y_test_rf_pred = rf_classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "V-onIT-A27JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mEQe9kdbgan"
      },
      "outputs": [],
      "source": [
        "# Training and testing accuracy\n",
        "rf_training_accuracy1 = accuracy_score(y_train,y_train_rf_pred)\n",
        "rf_testing_accuracy1 = accuracy_score(y_test,y_test_rf_pred)\n",
        "\n",
        "print('Training Accuracy of Random Forest:',rf_training_accuracy1)\n",
        "print('Testing Accuracy of Random Forest:',rf_testing_accuracy1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfW7JuqWbgan"
      },
      "outputs": [],
      "source": [
        "# Get scores like precision,recall, f1 score,roc_auc_score, confusion matrix\n",
        "  # precision,\n",
        "rf_test_precision1 = precision_score(y_test,y_test_rf_pred)\n",
        "\n",
        "  # recall,\n",
        "rf_test_recall1 = recall_score(y_test,y_test_rf_pred,)\n",
        "\n",
        "  # f1 score\n",
        "rf_f1_score1 = f1_score(y_test,y_test_rf_pred)\n",
        "\n",
        "  # roc_auc_score\n",
        "rf_roc_auc_score1 = roc_auc_score(y_test,y_test_rf_pred)\n",
        "\n",
        "  # confusion matrix\n",
        "rf_confusion_mat = confusion_matrix(y_test,y_test_rf_pred)\n",
        "\n",
        "  # Printing all these matrices\n",
        "print('Precision score of RANDOM FOREST model:',rf_test_precision1)\n",
        "print(' ')\n",
        "print('Recall score of RANDOM FOREST model:', rf_test_recall1)\n",
        "print(' ')\n",
        "print('F1 score of RANDOM FOREST model: ', rf_f1_score1)\n",
        "print(' ')\n",
        "print('ROC AUC score of RANDOM FOREST model: ',rf_roc_auc_score1)\n",
        "print(' ')\n",
        "print('Confusion matrix of RANDOM FOREST \\n:',rf_confusion_mat)\n",
        "print(' ')\n",
        "labels = ['Not At Risk','At Risk']\n",
        "\n",
        "# plotting confusion matrix through heatmap\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(rf_confusion_mat,cmap = 'Greens', annot = True, xticklabels = labels, yticklabels = labels)\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predcted Class')\n",
        "plt.title('Confusion Matrix of RANDOM FOREST',fontsize = 12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Model Used:**\n",
        "I used a **Random Forest Classifier**.\n",
        "Random Forest is an ensemble method that builds many decision trees and combines their results to make more accurate and stable predictions.\n",
        "It is widely used because it handles complex relationships and reduces the risk of overfitting compared to a single decision tree.\n",
        "\n",
        "\n",
        "\n",
        "**Model Performance:**\n",
        "\n",
        "* **Training Accuracy:** ~97%\n",
        "\n",
        "* **Testing Accuracy:** ~81%\n",
        "  *The model performs very well on training data and also generalizes well on testing data, though the high training accuracy compared to testing accuracy shows a bit of overfitting.*\n",
        "\n",
        "* **Precision:** ~81%\n",
        "  *When the model predicts someone will have CHD, it is correct 82% of the time.*\n",
        "\n",
        "* **Recall:** ~82%\n",
        "  *Out of all people who actually have CHD, the model correctly identifies about 82% of them.*\n",
        "\n",
        "* **F1 Score:** ~81%\n",
        "  *A good balance between precision and recall.*\n",
        "\n",
        "* **ROC AUC Score:** ~81%\n",
        "  *The model can distinguish between CHD and non‑CHD cases about 82% of the time.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The **Random Forest model** shows strong performance with an overall testing accuracy of ~81%.\n",
        "\n",
        "It balances well between catching true CHD cases (recall) and avoiding false positives (precision).\n",
        "\n",
        "While it has a very high training accuracy (~97%), which suggests some overfitting, its testing metrics still indicate it is a robust and reliable model for predicting CHD.\n",
        "\n"
      ],
      "metadata": {
        "id": "yPeLvT78l5-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Create base model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create GridSearchCV object\n",
        "rf_grid_model = GridSearchCV(rf_model,rf_param_grid,scoring='precision', cv=3,n_jobs=-1,verbose=1)\n",
        "\n",
        "# Fit the model\n",
        "rf_grid_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best parameter\n",
        "rf_grid_model.best_params_"
      ],
      "metadata": {
        "id": "acKud3Jz4OrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_train_rf_pred = rf_grid_model.predict(X_train)\n",
        "y_test_rf_pred = rf_grid_model.predict(X_test)"
      ],
      "metadata": {
        "id": "VIR68Qlg4Uvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing accuracy\n",
        "rf_training_accuracy1 = accuracy_score(y_train,y_train_rf_pred)\n",
        "rf_testing_accuracy1 = accuracy_score(y_test,y_test_rf_pred)\n",
        "\n",
        "print('Training Accuracy of Random Forest:',rf_training_accuracy1)\n",
        "print('Testing Accuracy of Random Forest:',rf_testing_accuracy1)"
      ],
      "metadata": {
        "id": "eDzOjbuI4q0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get scores like precision,recall, f1 score,roc_auc_score, confusion matrix\n",
        "  # precision,\n",
        "rf_test_precision1_cv = precision_score(y_test,y_test_rf_pred)\n",
        "\n",
        "  # recall,\n",
        "rf_test_recall1_cv = recall_score(y_test,y_test_rf_pred,)\n",
        "\n",
        "  # f1 score\n",
        "rf_f1_score1_cv = f1_score(y_test,y_test_rf_pred)\n",
        "\n",
        "  # roc_auc_score\n",
        "rf_roc_auc_score1_cv = roc_auc_score(y_test,y_test_rf_pred)\n",
        "\n",
        "  # confusion matrix\n",
        "rf_confusion_mat_cv = confusion_matrix(y_test,y_test_rf_pred)\n",
        "\n",
        "  # Printing all these matrices\n",
        "print('Precision score of RANDOM FOREST model:',rf_test_precision1_cv)\n",
        "print(' ')\n",
        "print('Recall score of RANDOM FOREST model:', rf_test_recall1_cv)\n",
        "print(' ')\n",
        "print('F1 score of RANDOM FOREST model: ', rf_f1_score1_cv)\n",
        "print(' ')\n",
        "print('ROC AUC score of RANDOM FOREST model: ',rf_roc_auc_score1_cv)\n",
        "print(' ')\n",
        "print('Confusion matrix of RANDOM FOREST \\n:',rf_confusion_mat_cv)\n",
        "print(' ')\n",
        "labels = ['Not At Risk','At Risk']\n",
        "\n",
        "# plotting confusion matrix through heatmap\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(rf_confusion_mat_cv,cmap = 'Greens', annot = True, xticklabels = labels, yticklabels = labels)\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predcted Class')\n",
        "plt.title('Confusion Matrix of RANDOM FOREST',fontsize = 12)"
      ],
      "metadata": {
        "id": "BBgp1iyt4YaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Model Used:**\n",
        "* I used a **Random Forest model with GridSearchCV tuning**.\n",
        "Random Forest is an ensemble method that builds many decision trees and combines their results.\n",
        "* It’s great at handling complex data and usually gives high accuracy and robustness by reducing overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Model Performance:**\n",
        "\n",
        "* **Training Accuracy:** ~94%\n",
        "\n",
        "* **Testing Accuracy:** ~85%\n",
        "  *The model performs very well on both training and testing data, showing good generalization and improved accuracy after tuning.*\n",
        "\n",
        "* **Precision:** ~87%\n",
        "  *When the model predicts someone will have CHD, it is correct about 87% of the time.*\n",
        "\n",
        "* **Recall:** ~82%\n",
        "  *Out of all people who actually have CHD, the model correctly identifies about 82% of them.*\n",
        "\n",
        "* **F1 Score:** ~84%\n",
        "  *This shows a strong balance between precision and recall.*\n",
        "\n",
        "* **ROC AUC Score:** ~85%\n",
        "  *The model can distinguish between CHD and non‑CHD cases about 85% of the time.*\n",
        "\n",
        "\n",
        "\n",
        "The **Random Forest model (tuned with GridSearchCV)** performs strongly with a testing accuracy of about 85%.\n",
        "\n",
        "It not only predicts CHD with high precision but also successfully captures most of the true CHD cases. This makes it a powerful and reliable model for this dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3: Decision Tree Classifier"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building decision tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtc = DecisionTreeClassifier(max_depth=5,             # Limit tree depth\n",
        "    min_samples_split=10,    # Require at least 10 samples to split\n",
        "    min_samples_leaf=5,      # Each leaf must have at least 5 samples\n",
        "    criterion='gini',        # Or use 'entropy'\n",
        "    random_state=42)\n",
        "\n",
        "dtc.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting train and test predicted values\n",
        "y_train_dtc_pred = dtc.predict(X_train)\n",
        "y_test_dtc_pred = dtc.predict(X_test)\n",
        "\n",
        "# Getting the training and testing accuracy\n",
        "dtc_training_accuracy1 = accuracy_score(y_train,y_train_dtc_pred)\n",
        "dtc_testing_accuracy1 = accuracy_score(y_test, y_test_dtc_pred)\n",
        "\n",
        "print('Training accuracy of decision tree classifier:',dtc_training_accuracy1)\n",
        "print('Testing accuracy of decision tree classifier:',dtc_testing_accuracy1)"
      ],
      "metadata": {
        "id": "UrtGsdPW6bKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get scores like precision,recall, f1 score,roc_auc_score, confusion matrix\n",
        "  # precision,\n",
        "dt_test_precision1 = precision_score(y_test,y_test_dtc_pred)\n",
        "\n",
        "  # recall,\n",
        "dt_test_recall1 = recall_score(y_test,y_test_dtc_pred,)\n",
        "\n",
        "  # f1 score\n",
        "dt_f1_score1 = f1_score(y_test,y_test_dtc_pred)\n",
        "\n",
        "  # roc_auc_score\n",
        "dt_roc_auc_score1 = roc_auc_score(y_test,y_test_dtc_pred)\n",
        "\n",
        "  # confusion matrix\n",
        "dt_confusion_mat = confusion_matrix(y_test,y_test_dtc_pred)\n",
        "\n",
        "  # Printing all these matrices\n",
        "print('Precision score of Decision Tree model:',dt_test_precision1)\n",
        "print(' ')\n",
        "print('Recall score of Decision Tree model:', dt_test_recall1)\n",
        "print(' ')\n",
        "print('F1 score of Decision Tree model: ', dt_f1_score1)\n",
        "print(' ')\n",
        "print('ROC AUC score of Decision Tree model: ',dt_roc_auc_score1)\n",
        "print(' ')\n",
        "print('Confusion matrix of Decision Tree model \\n:',dt_confusion_mat)\n",
        "print(' ')\n",
        "labels = ['Not At Risk','At Risk']\n",
        "\n",
        "# plotting confusion matrix through heatmap\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(dt_confusion_mat,cmap = 'Greens', annot = True, xticklabels = labels, yticklabels = labels)\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predcted Class')\n",
        "plt.title('Confusion Matrix of Decision Tree Model',fontsize = 12)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Model Used:**\n",
        "* I used a **Decision Tree Classifier**.\n",
        "A Decision Tree works by splitting the data into smaller and smaller groups based on feature values, creating a tree‑like structure that makes predictions. * It is simple to understand and interpret.\n",
        "\n",
        "\n",
        "\n",
        "**Model Performance:**\n",
        "\n",
        "* **Training Accuracy:** ~75%\n",
        "\n",
        "* **Testing Accuracy:** ~75%\n",
        "  *The model performs similarly on training and testing data, meaning it is not overfitting and gives consistent results.*\n",
        "\n",
        "* **Precision:** ~79%\n",
        "  *When the model predicts someone will have CHD, it is correct about 80% of the time.*\n",
        "\n",
        "* **Recall:** ~68%\n",
        "  *Out of all people who actually have CHD, the model correctly identifies about 68% of them.*\n",
        "\n",
        "* **F1 Score:** ~73%\n",
        "  *This shows a reasonable balance between precision and recall.*\n",
        "\n",
        "* **ROC AUC Score:** ~75%\n",
        "  *The model can distinguish between CHD and non‑CHD cases about 75% of the time.*\n",
        "\n",
        "-\n",
        "\n",
        "\n",
        "The **Decision Tree model** performs fairly well with a testing accuracy of about 75%.\n",
        "\n",
        "It is good at predicting CHD with around 80% precision and captures a fair portion of true CHD cases, making it a simple yet useful model for this dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "tEBJmM8pxjdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building decision tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "decision_tree_model = GridSearchCV(dtc, param_grid = {'max_depth': [2,4,6,8],\n",
        "                                                      'min_samples_leaf': [2,4,6,8,10],\n",
        "                                                      'min_samples_split':[2,4,6,8,10]},\n",
        "                                   scoring = 'recall',cv = 3, n_jobs = -1)\n",
        "decision_tree_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree_model.best_estimator_\n",
        "decision_tree_model.best_params_\n",
        "decision_tree_model.best_score_"
      ],
      "metadata": {
        "id": "lDIrLqce6D-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting train and test predicted values\n",
        "y_train_dtc_pred = decision_tree_model.predict(X_train)\n",
        "y_test_dtc_pred = decision_tree_model.predict(X_test)\n",
        "\n",
        "# Getting the training and testing accuracy\n",
        "dtc_training_accuracy1 = accuracy_score(y_train,y_train_dtc_pred)\n",
        "dtc_testing_accuracy1 = accuracy_score(y_test, y_test_dtc_pred)\n",
        "\n",
        "print('Training accuracy of decision tree classifier:',dtc_training_accuracy1)\n",
        "print('Testing accuracy of decision tree classifier:',dtc_testing_accuracy1)"
      ],
      "metadata": {
        "id": "cSMRsQZR6HNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get scores like precision,recall, f1 score,roc_auc_score, confusion matrix\n",
        "  # precision,\n",
        "dt_test_precision1_cv = precision_score(y_test,y_test_dtc_pred)\n",
        "\n",
        "  # recall,\n",
        "dt_test_recall1_cv = recall_score(y_test,y_test_dtc_pred,)\n",
        "\n",
        "  # f1 score\n",
        "dt_f1_score1_cv = f1_score(y_test,y_test_dtc_pred)\n",
        "\n",
        "  # roc_auc_score\n",
        "dt_roc_auc_score1_cv = roc_auc_score(y_test,y_test_dtc_pred)\n",
        "\n",
        "  # confusion matrix\n",
        "dt_confusion_mat_cv = confusion_matrix(y_test,y_test_dtc_pred)\n",
        "\n",
        "  # Printing all these matrices\n",
        "print('Precision score of Decision Tree model:',dt_test_precision1_cv)\n",
        "print(' ')\n",
        "print('Recall score of Decision Tree model:', dt_test_recall1_cv)\n",
        "print(' ')\n",
        "print('F1 score of Decision Tree model: ', dt_f1_score1_cv)\n",
        "print(' ')\n",
        "print('ROC AUC score of Decision Tree model: ',dt_roc_auc_score1_cv)\n",
        "print(' ')\n",
        "print('Confusion matrix of Decision Tree model \\n:',dt_confusion_mat_cv)\n",
        "print(' ')\n",
        "labels = ['Not At Risk','At Risk']\n",
        "\n",
        "# plotting confusion matrix through heatmap\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(dt_confusion_mat_cv,cmap = 'Greens', annot = True, xticklabels = labels, yticklabels = labels)\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predcted Class')\n",
        "plt.title('Confusion Matrix of Decision Tree Model',fontsize = 12)"
      ],
      "metadata": {
        "id": "GbjZeBUv6K7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Used:**\n",
        "* I used a Decision Tree Classifier with GridSearchCV (hyperparameter tuning).\n",
        "* A Decision Tree splits the data based on feature values, and using GridSearchCV helps find the best parameters to improve accuracy and generalization.\n",
        "\n"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Performance:**\n",
        "\n",
        "* **Training Accuracy:** ~84%\n",
        "\n",
        "* **Testing Accuracy:** ~78%\n",
        "  *The model performs well on both training and testing data, showing better generalization after tuning.*\n",
        "\n",
        "* **Precision:** ~78%\n",
        "  *When the model predicts someone will have CHD, it is correct about 78% of the time.*\n",
        "\n",
        "* **Recall:** ~80%\n",
        "  *Out of all people who actually have CHD, the model correctly identifies about 80% of them.*\n",
        "\n",
        "* **F1 Score:** ~79%\n",
        "  *This shows a good balance between precision and recall.*\n",
        "\n",
        "* **ROC AUC Score:** ~78%\n",
        "  *The model can distinguish between CHD and non‑CHD cases about 79% of the time.*\n",
        "\n",
        "\n",
        "\n",
        "The **Decision Tree model with GridSearchCV** shows improved performance compared to the default version.\n",
        "\n",
        "It achieves a testing accuracy of around 79%, balances precision and recall well, and benefits from hyperparameter tuning for better results on unseen data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 4: XGBoost"
      ],
      "metadata": {
        "id": "tu64YTS_xiYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Fitting XGboost\n",
        "xgb = XGBClassifier(class_weight = 'balanced',parameters = {'max_depth':7,'eta':1,'silent':1,'eval_metric':'auc'},random_state = 42)\n",
        "xgb.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "dtoz-BloxiY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test prediction\n",
        "y_train_xgb_pred = xgb.predict(X_train)\n",
        "y_test_xgb_pred = xgb.predict(X_test)\n"
      ],
      "metadata": {
        "id": "T_73MOUI8sVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "CHV1MKNMxiY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gettig training and testing accuracy\n",
        "xgb_training_accuracy1 = accuracy_score(y_train_xgb_pred,y_train)\n",
        "xgb_testing_accuracy1 = accuracy_score(y_test_xgb_pred,y_test)\n",
        "\n",
        "print(f'Training Accuracy of XGBClassifier: {xgb_training_accuracy1}')\n",
        "print(f'Testing Accuracy of XGBClassifier: {xgb_testing_accuracy1}')"
      ],
      "metadata": {
        "id": "ccPX_5Lj8v3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Get scores like precision,recall, f1 score,roc_auc_score, confusion matrix\n",
        "  # precision,\n",
        "xg_test_precision= precision_score(y_test,y_test_xgb_pred)\n",
        "\n",
        "  # recall,\n",
        "xg_test_recall1 = recall_score(y_test,y_test_xgb_pred,)\n",
        "\n",
        "  # f1 score\n",
        "xg_f1_score1 = f1_score(y_test,y_test_xgb_pred)\n",
        "\n",
        "  # roc_auc_score\n",
        "xg_roc_auc_score1 = roc_auc_score(y_test,y_test_xgb_pred)\n",
        "\n",
        "  # confusion matrix\n",
        "xg_confusion_mat1 = confusion_matrix(y_test,y_test_xgb_pred)\n",
        "\n",
        "  # Printing all these matrices\n",
        "print('Precision score of XGBoost model:',xg_test_precision)\n",
        "print(' ')\n",
        "print('Recall score of XGBoost model:', xg_test_recall1)\n",
        "print(' ')\n",
        "print('F1 score of XGBoost model: ', xg_f1_score1)\n",
        "print(' ')\n",
        "print('ROC AUC score of XGBoost model: ',xg_roc_auc_score1)\n",
        "print(' ')\n",
        "print('Confusion matrix of XGBoost model \\n:',xg_confusion_mat1)\n",
        "print(' ')\n",
        "labels = ['Not At Risk','At Risk']\n",
        "\n",
        "# plotting confusion matrix through heatmap\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(xg_confusion_mat1,cmap = 'Greens', annot = True, xticklabels = labels, yticklabels = labels)\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predcted Class')\n",
        "plt.title('Confusion Matrix of XGBoost Model',fontsize = 12)"
      ],
      "metadata": {
        "id": "BX_GikpexiY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Model Used:**\n",
        "\n",
        "* I used an **XGBoost Classifier**.\n",
        "\n",
        "* XGBoost is a powerful gradient boosting algorithm that builds many decision trees in sequence, each one learning from the errors of the previous ones. It is known for high accuracy and efficiency.\n",
        "\n",
        "\n",
        "**Model Performance:**\n",
        "\n",
        "* **Training Accuracy:** ~99%\n",
        "\n",
        "* **Testing Accuracy:** ~88%\n",
        "  *The model learns very well on training data and also performs strongly on unseen data, showing good generalization.*\n",
        "\n",
        "* **Precision:** ~90%\n",
        "  *When the model predicts someone will have CHD, it is correct about 91% of the time.*\n",
        "\n",
        "* **Recall:** ~85%\n",
        "  *Out of all people who actually have CHD, the model correctly identifies about 86% of them.*\n",
        "\n",
        "* **F1 Score:** ~88%\n",
        "  *This shows a strong balance between precision and recall.*\n",
        "\n",
        "* **ROC AUC Score:** ~88%\n",
        "  *The model can distinguish between CHD and non‑CHD cases about 88% of the time.*\n",
        "\n",
        "\n",
        "The **XGBoost Classifier** performs excellently with a testing accuracy of around **88%**.\n",
        "\n",
        "It is very precise in its predictions and captures most of the actual CHD cases, making it a strong choice for this dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "uQFQAz0eyrpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "i-u4mS_vxiY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Base model (NOTE: no 'parameters' arg here — it's for internal use only)\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],   # eta\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_xgb = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid,\n",
        "    scoring='precision',  # or 'roc_auc', 'f1', etc.\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "me-CcYaixiY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameters\n",
        "print(\"Best parameters:\", grid_xgb.best_params_)"
      ],
      "metadata": {
        "id": "eVWyhXKv-G4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "y_train_xgb_pred = grid_xgb.predict(X_train)\n",
        "y_test_xgb_pred = grid_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "Zc9_DMOw-MRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Evaluate\n",
        "print(\"Train Accuracy:\", accuracy_score(y_train, y_train_xgb_pred))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_xgb_pred))"
      ],
      "metadata": {
        "id": "IgprqCCc-Q4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Get scores like precision,recall, f1 score,roc_auc_score, confusion matrix\n",
        "  # precision,\n",
        "xg_test_precision_cv= precision_score(y_test,y_test_xgb_pred)\n",
        "\n",
        "  # recall,\n",
        "xg_test_recall1_cv = recall_score(y_test,y_test_xgb_pred,)\n",
        "\n",
        "  # f1 score\n",
        "xg_f1_score1_cv = f1_score(y_test,y_test_xgb_pred)\n",
        "\n",
        "  # roc_auc_score\n",
        "xg_roc_auc_score1_cv = roc_auc_score(y_test,y_test_xgb_pred)\n",
        "\n",
        "  # confusion matrix\n",
        "xg_confusion_mat1_cv = confusion_matrix(y_test,y_test_xgb_pred)\n",
        "\n",
        "  # Printing all these matrices\n",
        "print('Precision score of XGBoost model:',xg_test_precision_cv)\n",
        "print(' ')\n",
        "print('Recall score of XGBoost model:', xg_test_recall1_cv)\n",
        "print(' ')\n",
        "print('F1 score of XGBoost model: ', xg_f1_score1_cv)\n",
        "print(' ')\n",
        "print('ROC AUC score of XGBoost model: ',xg_roc_auc_score1_cv)\n",
        "print(' ')\n",
        "print('Confusion matrix of XGBoost model \\n:',xg_confusion_mat1_cv)\n",
        "print(' ')\n",
        "labels = ['Not At Risk','At Risk']\n",
        "\n",
        "# plotting confusion matrix through heatmap\n",
        "plt.figure(figsize = (9,6))\n",
        "sns.heatmap(xg_confusion_mat1_cv,cmap = 'Greens', annot = True, xticklabels = labels, yticklabels = labels)\n",
        "plt.ylabel('Actual Class')\n",
        "plt.xlabel('Predcted Class')\n",
        "plt.title('Confusion Matrix of XGBoost Model',fontsize = 12)"
      ],
      "metadata": {
        "id": "Bdgr82nm-Y8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "SiLjeIYYxiY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Model Used:**\n",
        "* I used an **XGBoost Classifier with GridSearchCV tuning**.\n",
        "* XGBoost is a gradient boosting algorithm that builds multiple decision trees in sequence, each improving on the mistakes of the previous ones.\n",
        "* Using **GridSearchCV** helped to find the best hyperparameters to improve accuracy and performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2xW3XPvxiY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "nw5iHaYQxiY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Model Performance:**\n",
        "\n",
        "* **Training Accuracy:** ~90%\n",
        "\n",
        "* **Testing Accuracy:** ~88%\n",
        "  *The model performs very well on both training and testing data, showing good generalization.*\n",
        "\n",
        "* **Precision:** ~94%\n",
        "  *When the model predicts someone will have CHD, it is correct about 95% of the time.*\n",
        "\n",
        "* **Recall:** ~82%\n",
        "  *Out of all people who actually have CHD, the model correctly identifies about 83% of them.*\n",
        "\n",
        "* **F1 Score:** ~88%\n",
        "  *This shows a strong balance between precision and recall.*\n",
        "\n",
        "* **ROC AUC Score:** ~88%\n",
        "  *The model can distinguish between CHD and non‑CHD cases about 89% of the time.*\n",
        "\n",
        "\n",
        "The **XGBoost Classifier (with GridSearchCV)** achieved a **testing accuracy of \\~88.87%**, with very high precision and strong recall.\n",
        "\n",
        "This makes it a highly effective model for predicting CHD, offering both reliability and robustness after tuning.\n",
        "\n"
      ],
      "metadata": {
        "id": "zv98xAtfxiY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Matrix"
      ],
      "metadata": {
        "id": "mFd9iYVluk75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Models = [\n",
        "    'Logistic Regression (Default)', 'Logistic Regression (Tuned)',\n",
        "    'Random Forest (Default)', 'Random Forest (Tuned)',\n",
        "    'Decision Tree (Default)', 'Decision Tree (Tuned)',\n",
        "    'XGBoost (Default)', 'XGBoost (Tuned)'\n",
        "]\n",
        "# Precision scores\n",
        "precision_scores = [\n",
        "    log_test_precision1, log_test_precision1_cv,\n",
        "    rf_test_precision1, rf_test_precision1_cv,\n",
        "    dt_test_precision1, dt_test_precision1_cv,\n",
        "    xg_test_precision, xg_test_precision_cv\n",
        "]\n",
        "\n",
        "# Recall scores\n",
        "recall_scores = [\n",
        "    log_test_recall1, log_test_recall1_cv,\n",
        "    rf_test_recall1, rf_test_recall1_cv,\n",
        "    dt_test_recall1, dt_test_recall1_cv,\n",
        "    xg_test_recall1, xg_test_recall1_cv\n",
        "]\n",
        "\n",
        "# F1 scores\n",
        "f1_scores = [\n",
        "    log_f1_score1, log_f1_score1_cv,\n",
        "    rf_f1_score1, rf_f1_score1_cv ,\n",
        "    dt_f1_score1, dt_f1_score1_cv,\n",
        "    xg_f1_score1, xg_f1_score1_cv\n",
        "]\n",
        "\n",
        "# ROC-AUC scores\n",
        "roc_auc_scores = [\n",
        "    log_roc_auc_score1, log_roc_auc_score1_cv,\n",
        "    rf_roc_auc_score1, rf_roc_auc_score1_cv,\n",
        "    dt_roc_auc_score1, dt_roc_auc_score1_cv,\n",
        "    xg_roc_auc_score1, xg_roc_auc_score1_cv\n",
        "]\n",
        "\n",
        "# Create the final DataFrame\n",
        "evaluation_matrix = pd.DataFrame({\n",
        "    'Model': Models,\n",
        "    'Precision Score': precision_scores,\n",
        "    'Recall Score': recall_scores,\n",
        "    'F1 Score': f1_scores,\n",
        "    'ROC-AUC Score': roc_auc_scores\n",
        "})\n",
        "\n",
        "# Display the table\n",
        "evaluation_matrix\n"
      ],
      "metadata": {
        "id": "Royy-vFW-vzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In our project, we looked at **Precision**, **Recall**, **F1 Score**, and **ROC‑AUC** to choose the best model.\n",
        "\n",
        "1. **Recall** tells us how many real heart‑risk patients we are able to catch.\n",
        "* This is important because missing a real patient could cost lives and lead to expensive treatments later.\n",
        "\n",
        "2. **Precision** tells us, out of the people we say are at risk, how many actually are.\n",
        "* This is important because too many false alarms waste time, money, and cause unnecessary worry.\n",
        "\n",
        "3. **F1 Score** is a balance between precision and recall.\n",
        "* This is important because we need both: catch as many true cases as possible but also avoid too many false alarms.\n",
        "\n",
        "4. **ROC‑AUC** tells us how well the model separates risky patients from healthy ones overall.\n",
        "* This is important for choosing the strongest model before setting a final threshold.\n",
        "\n",
        "\n",
        "\n",
        "We focused on recall, precision, F1, and ROC‑AUC to catch more true heart‑risk patients, avoid unnecessary tests, and choose a strong model that saves lives and reduces costs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the models you created, the **XGBoost (Default)** model is the best choice as the final prediction model as:-\n",
        "\n",
        "\n",
        "* It has the **highest F1 score (0.8771)**, meaning it gives the best balance between catching true heart‑risk patients and avoiding false alarms.\n",
        "* It also has a **high recall (0.8435)**, so it finds most of the patients at risk.\n",
        "* At the same time, it has a **high precision (0.9134)**, so it does not raise too many false alerts.\n",
        "* Its **ROC‑AUC (0.8818)** shows it separates risky and non‑risky patients very well.\n",
        "\n",
        "Tuned XGBoost had slightly higher precision, but its recall dropped compared to the default model.\n",
        "\n",
        "I chose **XGBoost (Default)** because it gives the most balanced and reliable results, helping catch more true cases while keeping false alarms low.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose XGBoost (Default) because it gives the most balanced and reliable results, helping catch more true cases while keeping false alarms low.\n",
        "ROC-AUC (~88%) and Precision ( ~91%)"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this project, we analyzed patient data and applied various machine learning models to predict the risk of cardiovascular disease. After comparing models using precision, recall, F1 score, and ROC‑AUC, **XGBoost (Default)** with ROC-AUC (~88%) and Precision ( ~91%), was selected as the final model because it provided the best balance between correctly identifying at‑risk patients and minimizing false alarms.\n",
        "\n",
        "This model can help in early detection of heart‑risk patients, allowing timely medical attention and reducing unnecessary tests, which leads to better health outcomes and cost savings. Overall, the project demonstrates how machine learning can support healthcare professionals in making faster and more accurate decisions.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}